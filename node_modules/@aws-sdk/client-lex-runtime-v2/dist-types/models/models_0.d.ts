/// <reference types="node" />
import { ExceptionOptionType as __ExceptionOptionType } from "@aws-sdk/smithy-client";
import { Readable } from "stream";
import { LexRuntimeV2ServiceException as __BaseException } from "./LexRuntimeV2ServiceException";
/**
 * <p></p>
 */
export declare class AccessDeniedException extends __BaseException {
    readonly name: "AccessDeniedException";
    readonly $fault: "client";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<AccessDeniedException, __BaseException>);
}
/**
 * <p>The time that a context is active. You can specify the time to live
 *          in seconds or in conversation turns.</p>
 */
export interface ActiveContextTimeToLive {
    /**
     * <p>The number of seconds that the context is active. You can specify
     *          between 5 and 86400 seconds (24 hours).</p>
     */
    timeToLiveInSeconds: number | undefined;
    /**
     * <p>The number of turns that the context is active. You can specify up
     *          to 20 turns. Each request and response from the bot is a turn.</p>
     */
    turnsToLive: number | undefined;
}
/**
 * <p>Contains information about the contexts that a user is using in a
 *          session. You can configure Amazon Lex V2 to set a context when an intent is
 *          fulfilled, or you can set a context using the , , or  operations.</p>
 *          <p>Use a context to indicate to Amazon Lex V2 intents that should be used as
 *          follow-up intents. For example, if the active context is
 *             <code>order-fulfilled</code>, only intents that have
 *             <code>order-fulfilled</code> configured as a trigger are considered
 *          for follow up.</p>
 */
export interface ActiveContext {
    /**
     * <p>The name of the context.</p>
     */
    name: string | undefined;
    /**
     * <p>Indicates the number of turns or seconds that the context is active.
     *          Once the time to live expires, the context is no longer returned in a
     *          response.</p>
     */
    timeToLive: ActiveContextTimeToLive | undefined;
    /**
     * <p>A list of contexts active for the request. A context can be
     *          activated when a previous intent is fulfilled, or by including the
     *          context in the request.</p>
     *          <p>If you don't specify a list of contexts, Amazon Lex V2 will use the current
     *          list of contexts for the session. If you specify an empty list, all
     *          contexts for the session are cleared. </p>
     */
    contextAttributes: Record<string, string> | undefined;
}
/**
 * <p>Represents a chunk of audio sent from the client application to
 *          Amazon Lex V2. The audio is all or part of an utterance from the user.</p>
 *          <p>Amazon Lex V2 accumulates audio chunks until it recognizes a natural pause
 *          in speech before processing the input.</p>
 */
export interface AudioInputEvent {
    /**
     * <p>An encoded stream of audio.</p>
     */
    audioChunk?: Uint8Array;
    /**
     * <p>The encoding used for the audio chunk. You must use 8 KHz PCM 16-bit
     *          mono-channel little-endian format. The value of the field should
     *          be:</p>
     *          <p>
     *             <code>audio/lpcm; sample-rate=8000; sample-size-bits=16;
     *             channel-count=1; is-big-endian=false</code>
     *          </p>
     */
    contentType: string | undefined;
    /**
     * <p>A unique identifier that your application assigns to the event. You
     *          can use this to identify events in logs.</p>
     */
    eventId?: string;
    /**
     * <p>A timestamp set by the client of the date and time that the event
     *          was sent to Amazon Lex V2.</p>
     */
    clientTimestampMillis?: number;
}
/**
 * <p>An event sent from Amazon Lex V2 to your client application containing audio
 *          to play to the user. </p>
 */
export interface AudioResponseEvent {
    /**
     * <p>A chunk of the audio to play. </p>
     */
    audioChunk?: Uint8Array;
    /**
     * <p>The encoding of the audio chunk. This is the same as the encoding
     *          configure in the <code>contentType</code> field of the
     *             <code>ConfigurationEvent</code>.</p>
     */
    contentType?: string;
    /**
     * <p>A unique identifier of the event sent by Amazon Lex V2. The identifier is in
     *          the form <code>RESPONSE-N</code>, where N is a number starting with one
     *          and incremented for each event sent by Amazon Lex V2 in the current
     *          session.</p>
     */
    eventId?: string;
}
/**
 * <p></p>
 */
export declare class ConflictException extends __BaseException {
    readonly name: "ConflictException";
    readonly $fault: "client";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<ConflictException, __BaseException>);
}
export interface DeleteSessionRequest {
    /**
     * <p>The identifier of the bot that contains the session data.</p>
     */
    botId: string | undefined;
    /**
     * <p>The alias identifier in use for the bot that contains the session
     *          data.</p>
     */
    botAliasId: string | undefined;
    /**
     * <p>The locale where the session is in use.</p>
     */
    localeId: string | undefined;
    /**
     * <p>The identifier of the session to delete.</p>
     */
    sessionId: string | undefined;
}
export interface DeleteSessionResponse {
    /**
     * <p>The identifier of the bot that contained the session data.</p>
     */
    botId?: string;
    /**
     * <p>The alias identifier in use for the bot that contained the session
     *          data.</p>
     */
    botAliasId?: string;
    /**
     * <p>The locale where the session was used.</p>
     */
    localeId?: string;
    /**
     * <p>The identifier of the deleted session.</p>
     */
    sessionId?: string;
}
/**
 * <p></p>
 */
export declare class InternalServerException extends __BaseException {
    readonly name: "InternalServerException";
    readonly $fault: "server";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<InternalServerException, __BaseException>);
}
/**
 * <p></p>
 */
export declare class ResourceNotFoundException extends __BaseException {
    readonly name: "ResourceNotFoundException";
    readonly $fault: "client";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<ResourceNotFoundException, __BaseException>);
}
/**
 * <p></p>
 */
export declare class ThrottlingException extends __BaseException {
    readonly name: "ThrottlingException";
    readonly $fault: "client";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<ThrottlingException, __BaseException>);
}
/**
 * <p></p>
 */
export declare class ValidationException extends __BaseException {
    readonly name: "ValidationException";
    readonly $fault: "client";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<ValidationException, __BaseException>);
}
export interface GetSessionRequest {
    /**
     * <p>The identifier of the bot that contains the session data.</p>
     */
    botId: string | undefined;
    /**
     * <p>The alias identifier in use for the bot that contains the session
     *          data.</p>
     */
    botAliasId: string | undefined;
    /**
     * <p>The locale where the session is in use.</p>
     */
    localeId: string | undefined;
    /**
     * <p>The identifier of the session to return.</p>
     */
    sessionId: string | undefined;
}
export declare enum ConfirmationState {
    CONFIRMED = "Confirmed",
    DENIED = "Denied",
    NONE = "None"
}
export declare enum Shape {
    COMPOSITE = "Composite",
    LIST = "List",
    SCALAR = "Scalar"
}
/**
 * <p>The value of a slot.</p>
 */
export interface Value {
    /**
     * <p>The text of the utterance from the user that was entered for the
     *          slot.</p>
     */
    originalValue?: string;
    /**
     * <p>The value that Amazon Lex V2 determines for the slot. The actual value
     *          depends on the setting of the value selection strategy for the bot. You
     *          can choose to use the value entered by the user, or you can have Amazon Lex V2
     *          choose the first value in the <code>resolvedValues</code> list.</p>
     */
    interpretedValue: string | undefined;
    /**
     * <p>A list of additional values that have been recognized for the
     *          slot.</p>
     */
    resolvedValues?: string[];
}
export declare enum IntentState {
    FAILED = "Failed",
    FULFILLED = "Fulfilled",
    FULFILLMENT_IN_PROGRESS = "FulfillmentInProgress",
    IN_PROGRESS = "InProgress",
    READY_FOR_FULFILLMENT = "ReadyForFulfillment",
    WAITING = "Waiting"
}
/**
 * <p>Provides a score that indicates the confidence that Amazon Lex V2 has that
 *          an intent is the one that satisfies the user's intent.</p>
 */
export interface ConfidenceScore {
    /**
     * <p>A score that indicates how confident Amazon Lex V2 is that an intent
     *          satisfies the user's intent. Ranges between 0.00 and 1.00. Higher
     *          scores indicate higher confidence.</p>
     */
    score?: number;
}
export declare enum SentimentType {
    MIXED = "MIXED",
    NEGATIVE = "NEGATIVE",
    NEUTRAL = "NEUTRAL",
    POSITIVE = "POSITIVE"
}
/**
 * <p>The individual sentiment responses for the utterance.</p>
 */
export interface SentimentScore {
    /**
     * <p>The level of confidence that Amazon Comprehend has in the accuracy
     *          of its detection of the <code>POSITIVE</code> sentiment.</p>
     */
    positive?: number;
    /**
     * <p>The level of confidence that Amazon Comprehend has in the accuracy
     *          of its detection of the <code>NEGATIVE</code> sentiment.</p>
     */
    negative?: number;
    /**
     * <p>The level of confidence that Amazon Comprehend has in the accuracy
     *          of its detection of the <code>NEUTRAL</code> sentiment.</p>
     */
    neutral?: number;
    /**
     * <p>The level of confidence that Amazon Comprehend has in the accuracy
     *          of its detection of the <code>MIXED</code> sentiment.</p>
     */
    mixed?: number;
}
/**
 * <p>Provides information about the sentiment expressed in a user's
 *          response in a conversation. Sentiments are determined using Amazon
 *          Comprehend. Sentiments are only returned if they are enabled for the
 *          bot.</p>
 *          <p>For more information, see <a href="https://docs.aws.amazon.com/comprehend/latest/dg/how-sentiment.html">
 *             Determine Sentiment </a> in the <i>Amazon Comprehend
 *             developer guide</i>.</p>
 */
export interface SentimentResponse {
    /**
     * <p>The overall sentiment expressed in the user's response. This is the
     *          sentiment most likely expressed by the user based on the analysis by
     *          Amazon Comprehend.</p>
     */
    sentiment?: SentimentType | string;
    /**
     * <p>The individual sentiment responses for the utterance.</p>
     */
    sentimentScore?: SentimentScore;
}
export declare enum MessageContentType {
    CUSTOM_PAYLOAD = "CustomPayload",
    IMAGE_RESPONSE_CARD = "ImageResponseCard",
    PLAIN_TEXT = "PlainText",
    SSML = "SSML"
}
/**
 * <p>A button that appears on a response card show to the user.</p>
 */
export interface Button {
    /**
     * <p>The text that is displayed on the button.</p>
     */
    text: string | undefined;
    /**
     * <p>The value returned to Amazon Lex V2 when a user chooses the button.</p>
     */
    value: string | undefined;
}
/**
 * <p>A card that is shown to the user by a messaging platform. You define
 *          the contents of the card, the card is displayed by the platform. </p>
 *          <p>When you use a response card, the response from the user is
 *          constrained to the text associated with a button on the card.</p>
 */
export interface ImageResponseCard {
    /**
     * <p>The title to display on the response card. The format of the title
     *          is determined by the platform displaying the response card.</p>
     */
    title: string | undefined;
    /**
     * <p>The subtitle to display on the response card. The format of the
     *          subtitle is determined by the platform displaying the response
     *          card.</p>
     */
    subtitle?: string;
    /**
     * <p>The URL of an image to display on the response card. The image URL
     *          must be publicly available so that the platform displaying the response
     *          card has access to the image.</p>
     */
    imageUrl?: string;
    /**
     * <p>A list of buttons that should be displayed on the response card. The
     *          arrangement of the buttons is determined by the platform that displays
     *          the button.</p>
     */
    buttons?: Button[];
}
/**
 * <p>Container for text that is returned to the customer..</p>
 */
export interface Message {
    /**
     * <p>The text of the message.</p>
     */
    content?: string;
    /**
     * <p>Indicates the type of response.</p>
     */
    contentType: MessageContentType | string | undefined;
    /**
     * <p>A card that is shown to the user by a messaging platform. You define
     *          the contents of the card, the card is displayed by the platform. </p>
     *          <p>When you use a response card, the response from the user is
     *          constrained to the text associated with a button on the card.</p>
     */
    imageResponseCard?: ImageResponseCard;
}
export declare enum StyleType {
    DEFAULT = "Default",
    SPELL_BY_LETTER = "SpellByLetter",
    SPELL_BY_WORD = "SpellByWord"
}
export declare enum DialogActionType {
    CLOSE = "Close",
    CONFIRM_INTENT = "ConfirmIntent",
    DELEGATE = "Delegate",
    ELICIT_INTENT = "ElicitIntent",
    ELICIT_SLOT = "ElicitSlot",
    NONE = "None"
}
/**
 * <p>Provides the phrase that Amazon Lex V2 should look for in the user's input
 *          to the bot.</p>
 */
export interface RuntimeHintValue {
    /**
     * <p>The phrase that Amazon Lex V2 should look for in the user's input to the
     *          bot.</p>
     */
    phrase: string | undefined;
}
/**
 * <p></p>
 */
export declare class BadGatewayException extends __BaseException {
    readonly name: "BadGatewayException";
    readonly $fault: "server";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<BadGatewayException, __BaseException>);
}
/**
 * <p></p>
 */
export declare class DependencyFailedException extends __BaseException {
    readonly name: "DependencyFailedException";
    readonly $fault: "client";
    /**
     * @internal
     */
    constructor(opts: __ExceptionOptionType<DependencyFailedException, __BaseException>);
}
export interface PutSessionResponse {
    /**
     * <p>The type of response. Same as the type specified in the
     *             <code>responseContentType</code> field in the request.</p>
     */
    contentType?: string;
    /**
     * <p>A list of messages that were last sent to the user. The messages are
     *          ordered based on how you return the messages from you Lambda function
     *          or the order that the messages are defined in the bot.</p>
     */
    messages?: string;
    /**
     * <p>Represents the current state of the dialog between the user and the
     *          bot.</p>
     *          <p>Use this to determine the progress of the conversation and what the
     *          next action may be.</p>
     */
    sessionState?: string;
    /**
     * <p>Request-specific information passed between the client application
     *          and Amazon Lex V2. These are the same as the <code>requestAttribute</code>
     *          parameter in the call to the <code>PutSession</code> operation.</p>
     */
    requestAttributes?: string;
    /**
     * <p>The identifier of the session that received the data.</p>
     */
    sessionId?: string;
    /**
     * <p>If the requested content type was audio, the audio version of the
     *          message to convey to the user.</p>
     */
    audioStream?: Readable | ReadableStream | Blob;
}
export interface RecognizeUtteranceRequest {
    /**
     * <p>The identifier of the bot that should receive the request.</p>
     */
    botId: string | undefined;
    /**
     * <p>The alias identifier in use for the bot that should receive the
     *          request.</p>
     */
    botAliasId: string | undefined;
    /**
     * <p>The locale where the session is in use.</p>
     */
    localeId: string | undefined;
    /**
     * <p>The identifier of the session in use.</p>
     */
    sessionId: string | undefined;
    /**
     * <p>Sets the state of the session with the user. You can use this to set
     *          the current intent, attributes, context, and dialog action. Use the
     *          dialog action to determine the next step that Amazon Lex V2 should use in the
     *          conversation with the user.</p>
     *          <p>The <code>sessionState</code> field must be compressed using gzip
     *          and then base64 encoded before sending to Amazon Lex V2.</p>
     */
    sessionState?: string;
    /**
     * <p>Request-specific information passed between the client application
     *          and Amazon Lex V2 </p>
     *          <p>The namespace <code>x-amz-lex:</code> is reserved for special
     *          attributes. Don't create any request attributes for prefix
     *             <code>x-amz-lex:</code>.</p>
     *          <p>The <code>requestAttributes</code> field must be compressed using
     *          gzip and then base64 encoded before sending to Amazon Lex V2.</p>
     */
    requestAttributes?: string;
    /**
     * <p>Indicates the format for audio input or that the content is text.
     *          The header must start with one of the following prefixes:</p>
     *          <ul>
     *             <li>
     *                <p>PCM format, audio data must be in little-endian byte
     *                order.</p>
     *                <ul>
     *                   <li>
     *                      <p>audio/l16; rate=16000; channels=1</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/x-l16; sample-rate=16000; channel-count=1</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/lpcm; sample-rate=8000; sample-size-bits=16;
     *                      channel-count=1; is-big-endian=false</p>
     *                   </li>
     *                </ul>
     *             </li>
     *             <li>
     *                <p>Opus format</p>
     *                <ul>
     *                   <li>
     *                      <p>audio/x-cbr-opus-with-preamble;preamble-size=0;bit-rate=256000;frame-size-milliseconds=4</p>
     *                   </li>
     *                </ul>
     *             </li>
     *             <li>
     *                <p>Text format</p>
     *                <ul>
     *                   <li>
     *                      <p>text/plain; charset=utf-8</p>
     *                   </li>
     *                </ul>
     *             </li>
     *          </ul>
     */
    requestContentType: string | undefined;
    /**
     * <p>The message that Amazon Lex V2 returns in the response can be either text or
     *          speech based on the <code>responseContentType</code> value.</p>
     *          <ul>
     *             <li>
     *                <p>If the value is <code>text/plain;charset=utf-8</code>, Amazon Lex V2
     *                returns text in the response.</p>
     *             </li>
     *             <li>
     *                <p>If the value begins with <code>audio/</code>, Amazon Lex V2 returns
     *                speech in the response. Amazon Lex V2 uses Amazon Polly to generate the speech
     *                using the configuration that you specified in the
     *                   <code>requestContentType</code> parameter. For example, if you
     *                specify <code>audio/mpeg</code> as the value, Amazon Lex V2 returns
     *                speech in the MPEG format.</p>
     *             </li>
     *             <li>
     *                <p>If the value is <code>audio/pcm</code>, the speech returned is
     *                   <code>audio/pcm</code> at 16 KHz in 16-bit, little-endian
     *                format.</p>
     *             </li>
     *             <li>
     *                <p>The following are the accepted values:</p>
     *                <ul>
     *                   <li>
     *                      <p>audio/mpeg</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/ogg</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/pcm (16 KHz)</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/* (defaults to mpeg)</p>
     *                   </li>
     *                   <li>
     *                      <p>text/plain; charset=utf-8</p>
     *                   </li>
     *                </ul>
     *             </li>
     *          </ul>
     */
    responseContentType?: string;
    /**
     * <p>User input in PCM or Opus audio format or text format as described
     *          in the <code>requestContentType</code> parameter.</p>
     */
    inputStream?: Readable | ReadableStream | Blob;
}
export interface RecognizeUtteranceResponse {
    /**
     * <p>Indicates whether the input mode to the operation was text or
     *          speech.
     *       </p>
     */
    inputMode?: string;
    /**
     * <p>Content type as specified in the <code>responseContentType</code> in
     *          the request.</p>
     */
    contentType?: string;
    /**
     * <p>A list of messages that were last sent to the user. The messages are
     *          ordered based on the order that you returned the messages from your
     *          Lambda function or the order that the messages are defined in the
     *          bot.</p>
     *          <p>The <code>messages</code> field is compressed with gzip and then
     *          base64 encoded. Before you can use the contents of the field, you must
     *          decode and decompress the contents. See the example for a simple
     *          function to decode and decompress the contents.</p>
     */
    messages?: string;
    /**
     * <p>A list of intents that Amazon Lex V2 determined might satisfy the user's
     *          utterance.</p>
     *          <p>Each interpretation includes the intent, a score that indicates how
     *          confident Amazon Lex V2 is that the interpretation is the correct one, and an
     *          optional sentiment response that indicates the sentiment expressed in
     *          the utterance.</p>
     *          <p>The <code>interpretations</code> field is compressed with gzip and
     *          then base64 encoded. Before you can use the contents of the field, you
     *          must decode and decompress the contents. See the example for a simple
     *          function to decode and decompress the contents.</p>
     */
    interpretations?: string;
    /**
     * <p>Represents the current state of the dialog between the user and the
     *          bot.</p>
     *          <p>Use this to determine the progress of the conversation and what the
     *          next action might be.</p>
     *          <p>The <code>sessionState</code> field is compressed with gzip and then
     *          base64 encoded. Before you can use the contents of the field, you must
     *          decode and decompress the contents. See the example for a simple
     *          function to decode and decompress the contents.</p>
     */
    sessionState?: string;
    /**
     * <p>The attributes sent in the request.</p>
     *          <p>The <code>requestAttributes</code> field is compressed with gzip and
     *          then base64 encoded. Before you can use the contents of the field, you
     *          must decode and decompress the contents.</p>
     */
    requestAttributes?: string;
    /**
     * <p>The identifier of the session in use.</p>
     */
    sessionId?: string;
    /**
     * <p>The text used to process the request.</p>
     *          <p>If the input was an audio stream, the <code>inputTranscript</code>
     *          field contains the text extracted from the audio stream. This is the
     *          text that is actually processed to recognize intents and slot values.
     *          You can use this information to determine if Amazon Lex V2 is correctly
     *          processing the audio that you send.</p>
     *          <p>The <code>inputTranscript</code> field is compressed with gzip and
     *          then base64 encoded. Before you can use the contents of the field, you
     *          must decode and decompress the contents. See the example for a simple
     *          function to decode and decompress the contents.</p>
     */
    inputTranscript?: string;
    /**
     * <p>The prompt or statement to send to the user. This is based on the
     *          bot configuration and context. For example, if Amazon Lex V2 did not understand
     *          the user intent, it sends the <code>clarificationPrompt</code>
     *          configured for the bot. If the intent requires confirmation before
     *          taking the fulfillment action, it sends the
     *             <code>confirmationPrompt</code>. Another example: Suppose that the
     *          Lambda function successfully fulfilled the intent, and sent a message
     *          to convey to the user. Then Amazon Lex V2 sends that message in the
     *          response.</p>
     */
    audioStream?: Readable | ReadableStream | Blob;
}
export declare enum ConversationMode {
    AUDIO = "AUDIO",
    TEXT = "TEXT"
}
/**
 * <p>A notification from the client that it is disconnecting from Amazon Lex V2.
 *          Sending a <code>DisconnectionEvent</code> event is optional, but can
 *          help identify a conversation in logs.</p>
 */
export interface DisconnectionEvent {
    /**
     * <p>A unique identifier that your application assigns to the event. You
     *          can use this to identify events in logs.</p>
     */
    eventId?: string;
    /**
     * <p>A timestamp set by the client of the date and time that the event
     *          was sent to Amazon Lex V2.</p>
     */
    clientTimestampMillis?: number;
}
/**
 * <p>A DTMF character sent from the client application. DTMF characters
 *          are typically sent from a phone keypad to represent numbers. For
 *          example, you can have Amazon Lex V2 process a credit card number input from a
 *          phone.</p>
 */
export interface DTMFInputEvent {
    /**
     * <p>The DTMF character that the user pressed. The allowed characters are
     *          A - D, 0 - 9, # and *.</p>
     */
    inputCharacter: string | undefined;
    /**
     * <p>A unique identifier that your application assigns to the event. You
     *          can use this to identify events in logs.</p>
     */
    eventId?: string;
    /**
     * <p>A timestamp set by the client of the date and time that the event
     *          was sent to Amazon Lex V2.</p>
     */
    clientTimestampMillis?: number;
}
/**
 * <p>Event sent from the client application to Amazon Lex V2 to indicate that
 *          playback of audio is complete and that Amazon Lex V2 should start processing
 *          the user's input.</p>
 */
export interface PlaybackCompletionEvent {
    /**
     * <p>A unique identifier that your application assigns to the event. You
     *          can use this to identify events in logs.</p>
     */
    eventId?: string;
    /**
     * <p>A timestamp set by the client of the date and time that the event
     *          was sent to Amazon Lex V2.</p>
     */
    clientTimestampMillis?: number;
}
/**
 * <p>The event sent from your client application to Amazon Lex V2 with text input
 *          from the user.</p>
 */
export interface TextInputEvent {
    /**
     * <p>The text from the user. Amazon Lex V2 processes this as a complete
     *          statement.</p>
     */
    text: string | undefined;
    /**
     * <p>A unique identifier that your application assigns to the event. You
     *          can use this to identify events in logs.</p>
     */
    eventId?: string;
    /**
     * <p>A timestamp set by the client of the date and time that the event
     *          was sent to Amazon Lex V2.</p>
     */
    clientTimestampMillis?: number;
}
/**
 * <p>Event that Amazon Lex V2 sends to indicate that the stream is still open
 *          between the client application and Amazon Lex V2 </p>
 */
export interface HeartbeatEvent {
    /**
     * <p>A unique identifier of the event sent by Amazon Lex V2. The identifier is in
     *          the form <code>RESPONSE-N</code>, where N is a number starting with one
     *          and incremented for each event sent by Amazon Lex V2 in the current
     *          session.</p>
     */
    eventId?: string;
}
export declare enum InputMode {
    DTMF = "DTMF",
    SPEECH = "Speech",
    TEXT = "Text"
}
export declare enum PlaybackInterruptionReason {
    DTMF_START_DETECTED = "DTMF_START_DETECTED",
    TEXT_DETECTED = "TEXT_DETECTED",
    VOICE_START_DETECTED = "VOICE_START_DETECTED"
}
/**
 * <p>Event sent from Amazon Lex V2 to indicate to the client application should
 *          stop playback of audio. For example, if the client is playing a prompt
 *          that asks for the user's telephone number, the user might start to say
 *          the phone number before the prompt is complete. Amazon Lex V2 sends this event
 *          to the client application to indicate that the user is responding and
 *          that Amazon Lex V2 is processing their input.</p>
 */
export interface PlaybackInterruptionEvent {
    /**
     * <p>Indicates the type of user input that Amazon Lex V2 detected.</p>
     */
    eventReason?: PlaybackInterruptionReason | string;
    /**
     * <p>The identifier of the event that contained the audio, DTMF, or text
     *          that caused the interruption.</p>
     */
    causedByEventId?: string;
    /**
     * <p>A unique identifier of the event sent by Amazon Lex V2. The identifier is in
     *          the form <code>RESPONSE-N</code>, where N is a number starting with one
     *          and incremented for each event sent by Amazon Lex V2 in the current
     *          session.</p>
     */
    eventId?: string;
}
/**
 * <p>The event sent from Amazon Lex V2 to your application with text to present
 *          to the user.</p>
 */
export interface TextResponseEvent {
    /**
     * <p>A list of messages to send to the user. Messages are ordered based
     *          on the order that you returned the messages from your Lambda function
     *          or the order that the messages are defined in the bot.</p>
     */
    messages?: Message[];
    /**
     * <p>A unique identifier of the event sent by Amazon Lex V2. The identifier is in
     *          the form <code>RESPONSE-N</code>, where N is a number starting with one
     *          and incremented for each event sent by Amazon Lex V2 in the current
     *          session.</p>
     */
    eventId?: string;
}
/**
 * <p>Event sent from Amazon Lex V2 to your client application that contains a
 *          transcript of voice audio. </p>
 */
export interface TranscriptEvent {
    /**
     * <p>The transcript of the voice audio from the user.</p>
     */
    transcript?: string;
    /**
     * <p>A unique identifier of the event sent by Amazon Lex V2. The identifier is in
     *          the form <code>RESPONSE-N</code>, where N is a number starting with one
     *          and incremented for each event sent by Amazon Lex V2 in the current
     *          session.</p>
     */
    eventId?: string;
}
/**
 * <p>The specific constituent sub slot of the composite slot to elicit in dialog action.</p>
 */
export interface ElicitSubSlot {
    /**
     * <p>The name of the slot that should be elicited from the user.</p>
     */
    name: string | undefined;
    /**
     * <p>The field is not supported.</p>
     */
    subSlotToElicit?: ElicitSubSlot;
}
/**
 * <p>The next action that Amazon Lex V2 should take.</p>
 */
export interface DialogAction {
    /**
     * <p>The next action that the bot should take in its interaction with the
     *          user. The possible values are:</p>
     *          <ul>
     *             <li>
     *                <p>
     *                   <code>Close</code> - Indicates that there will not be a
     *                response from the user. For example, the statement "Your order
     *                has been placed" does not require a response.</p>
     *             </li>
     *             <li>
     *                <p>
     *                   <code>ConfirmIntent</code> - The next action is asking the
     *                user if the intent is complete and ready to be fulfilled. This is
     *                a yes/no question such as "Place the order?"</p>
     *             </li>
     *             <li>
     *                <p>
     *                   <code>Delegate</code> - The next action is determined by
     *                Amazon Lex V2.</p>
     *             </li>
     *             <li>
     *                <p>
     *                   <code>ElicitIntent</code> - The next action is to elicit an
     *                intent from the user.</p>
     *             </li>
     *             <li>
     *                <p>
     *                   <code>ElicitSlot</code> - The next action is to elicit a slot
     *                value from the user.</p>
     *             </li>
     *          </ul>
     */
    type: DialogActionType | string | undefined;
    /**
     * <p>The name of the slot that should be elicited from the user.</p>
     */
    slotToElicit?: string;
    /**
     * <p>Configures the slot to use spell-by-letter or spell-by-word style.
     *          When you use a style on a slot, users can spell out their input to make
     *          it clear to your bot.</p>
     *          <ul>
     *             <li>
     *                <p>Spell by letter - "b" "o" "b"</p>
     *             </li>
     *             <li>
     *                <p>Spell by word - "b as in boy" "o as in oscar" "b as in
     *                boy"</p>
     *             </li>
     *          </ul>
     *          <p>For more information, see <a href="https://docs.aws.amazon.com/lexv2/latest/dg/using-spelling.html">
     *             Using spelling to enter slot values </a>.</p>
     */
    slotElicitationStyle?: StyleType | string;
    /**
     * <p>The name of the constituent sub slot of the composite slot
     *       specified in slotToElicit that should be elicited from the user.</p>
     */
    subSlotToElicit?: ElicitSubSlot;
}
/**
 * <p>Provides an array of phrases that should be given preference when
 *          resolving values for a slot.</p>
 */
export interface RuntimeHintDetails {
    /**
     * <p>One or more strings that Amazon Lex V2 should look for in the input to the
     *          bot. Each phrase is given preference when deciding on slot
     *          values.</p>
     */
    runtimeHintValues?: RuntimeHintValue[];
    /**
     * <p>A map of constituent sub slot names inside a composite slot in the intent and the phrases
     *       that should be added for each sub slot. Inside each composite slot hints, this structure provides
     *       a mechanism to add granular sub slot phrases. Only sub slot hints are supported for composite slots.
     *       The intent name, composite slot name and the constituent sub slot names must exist.</p>
     */
    subSlotHints?: Record<string, RuntimeHintDetails>;
}
/**
 * <p>You can provide Amazon Lex V2 with hints to the phrases that a customer is
 *          likely to use for a slot. When a slot with hints is resolved, the
 *          phrases in the runtime hints are preferred in the resolution. You can
 *          provide hints for a maximum of 100 intents. You can provide a maximum
 *          of 100 slots.</p>
 *          <p>Before you can use runtime hints with an existing bot, you must
 *          first rebuild the bot.</p>
 *          <p>For more information, see <a href="https://docs.aws.amazon.com/lexv2/latest/dg/using-hints.html">Using runtime hints to
 *             improve recognition of slot values</a>.</p>
 */
export interface RuntimeHints {
    /**
     * <p>A list of the slots in the intent that should have runtime hints
     *          added, and the phrases that should be added for each slot.</p>
     *          <p>The first level of the <code>slotHints</code> map is the name of the
     *          intent. The second level is the name of the slot within the intent. For
     *          more information, see <a href="https://docs.aws.amazon.com/lexv2/latest/dg/using-hints.html">Using hints to improve
     *             accuracy</a>.</p>
     *          <p>The intent name and slot name must exist.</p>
     */
    slotHints?: Record<string, Record<string, RuntimeHintDetails>>;
}
/**
 * <p>A value that Amazon Lex V2 uses to fulfill an intent. </p>
 */
export interface Slot {
    /**
     * <p>The current value of the slot.</p>
     */
    value?: Value;
    /**
     * <p>When the <code>shape</code> value is <code>List</code>, it indicates
     *          that the <code>values</code> field contains a list of slot values. When
     *          the value is <code>Scalar</code>, it indicates that the
     *             <code>value</code> field contains a single value.</p>
     */
    shape?: Shape | string;
    /**
     * <p>A list of one or more values that the user provided for the slot.
     *          For example, if a for a slot that elicits pizza toppings, the values
     *          might be "pepperoni" and "pineapple." </p>
     */
    values?: Slot[];
    /**
     * <p>The constituent sub slots of a composite slot.</p>
     */
    subSlots?: Record<string, Slot>;
}
/**
 * <p>The current intent that Amazon Lex V2 is attempting to fulfill.</p>
 */
export interface Intent {
    /**
     * <p>The name of the intent.</p>
     */
    name: string | undefined;
    /**
     * <p>A map of all of the slots for the intent. The name of the slot maps
     *          to the value of the slot. If a slot has not been filled, the value is
     *          null.</p>
     */
    slots?: Record<string, Slot>;
    /**
     * <p>Contains fulfillment information for the intent. </p>
     */
    state?: IntentState | string;
    /**
     * <p>Contains information about whether fulfillment of the intent has
     *          been confirmed.</p>
     */
    confirmationState?: ConfirmationState | string;
}
/**
 * <p>An intent that Amazon Lex V2 determined might satisfy the user's utterance.
 *          The intents are ordered by the confidence score. </p>
 */
export interface Interpretation {
    /**
     * <p>Determines the threshold where Amazon Lex V2 will insert the
     *             <code>AMAZON.FallbackIntent</code>,
     *             <code>AMAZON.KendraSearchIntent</code>, or both when returning
     *          alternative intents in a response. <code>AMAZON.FallbackIntent</code>
     *          and <code>AMAZON.KendraSearchIntent</code> are only inserted if they
     *          are configured for the bot.</p>
     */
    nluConfidence?: ConfidenceScore;
    /**
     * <p>The sentiment expressed in an utterance. </p>
     *          <p>When the bot is configured to send utterances to Amazon Comprehend
     *          for sentiment analysis, this field contains the result of the
     *          analysis.</p>
     */
    sentimentResponse?: SentimentResponse;
    /**
     * <p>A list of intents that might satisfy the user's utterance. The
     *          intents are ordered by the confidence score.</p>
     */
    intent?: Intent;
}
/**
 * <p>The state of the user's session with Amazon Lex V2.</p>
 */
export interface SessionState {
    /**
     * <p>The next step that Amazon Lex V2 should take in the conversation with a
     *          user.</p>
     */
    dialogAction?: DialogAction;
    /**
     * <p>The active intent that Amazon Lex V2 is processing.</p>
     */
    intent?: Intent;
    /**
     * <p>One or more contexts that indicate to Amazon Lex V2 the context of a
     *          request. When a context is active, Amazon Lex V2 considers intents with the
     *          matching context as a trigger as the next intent in a session.</p>
     */
    activeContexts?: ActiveContext[];
    /**
     * <p>Map of key/value pairs representing session-specific context
     *          information. It contains application information passed between Amazon Lex V2
     *          and a client application.</p>
     */
    sessionAttributes?: Record<string, string>;
    /**
     * <p>A unique identifier for a specific request.</p>
     */
    originatingRequestId?: string;
    /**
     * <p>Hints for phrases that a customer is likely to use for a slot. Amazon Lex V2
     *          uses the hints to help determine the correct value of a slot.</p>
     */
    runtimeHints?: RuntimeHints;
}
/**
 * <p>The initial event sent from the application to Amazon Lex V2 to configure
 *          the conversation, including session and request attributes and the
 *          response content type.</p>
 */
export interface ConfigurationEvent {
    /**
     * <p>Request-specific information passed between the client application
     *          and Amazon Lex V2.</p>
     *          <p>The namespace <code>x-amz-lex:</code> is reserved for special
     *          attributes. Don't create any request attributes for prefix
     *             <code>x-amz-lex:</code>.</p>
     */
    requestAttributes?: Record<string, string>;
    /**
     * <p>The message that Amazon Lex V2 returns in the response can be either text or
     *          speech based on the <code>responseContentType</code> value.</p>
     *          <ul>
     *             <li>
     *                <p>If the value is <code>text/plain;charset=utf-8</code>, Amazon Lex V2
     *                returns text in the response.</p>
     *             </li>
     *             <li>
     *                <p>If the value begins with <code>audio/</code>, Amazon Lex V2 returns
     *                speech in the response. Amazon Lex V2 uses Amazon Polly to generate the speech
     *                using the configuration that you specified in the
     *                   <code>requestContentType</code> parameter. For example, if you
     *                specify <code>audio/mpeg</code> as the value, Amazon Lex V2 returns
     *                speech in the MPEG format.</p>
     *             </li>
     *             <li>
     *                <p>If the value is <code>audio/pcm</code>, the speech returned is
     *                audio/pcm in 16-bit, little-endian format.</p>
     *             </li>
     *             <li>
     *                <p>The following are the accepted values:</p>
     *                <ul>
     *                   <li>
     *                      <p>audio/mpeg</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/ogg</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/pcm</p>
     *                   </li>
     *                   <li>
     *                      <p>audio/* (defaults to mpeg)</p>
     *                   </li>
     *                   <li>
     *                      <p>text/plain; charset=utf-8</p>
     *                   </li>
     *                </ul>
     *             </li>
     *          </ul>
     */
    responseContentType: string | undefined;
    /**
     * <p>The state of the user's session with Amazon Lex V2.</p>
     */
    sessionState?: SessionState;
    /**
     * <p>A list of messages to send to the user.</p>
     *          <p>If you set the <code>welcomeMessage</code> field, you must also set
     *          the <a href="https://docs.aws.amazon.com/lexv2/latest/dg/API_runtime_DialogAction.html">
     *                <code>DialogAction</code>
     *             </a> structure's <a href="https://docs.aws.amazon.com/lexv2/latest/dg/API_runtime_DialogAction.html#lexv2-Type-runtime_DialogAction-type">
     *                <code>type</code>
     *             </a> field.</p>
     */
    welcomeMessages?: Message[];
    /**
     * <p>Determines whether Amazon Lex V2 should send audio responses to the client
     *          application.
     *       </p>
     *          <p>Set this field to false when the client is operating in a playback
     *          mode where audio responses are played to the user. If the client isn't
     *          operating in playback mode, such as a text chat application, set this
     *          to true so that Amazon Lex V2 doesn't wait for the prompt to finish playing on
     *          the client.</p>
     */
    disablePlayback?: boolean;
    /**
     * <p>A unique identifier that your application assigns to the event. You
     *          can use this to identify events in logs.</p>
     */
    eventId?: string;
    /**
     * <p>A timestamp set by the client of the date and time that the event
     *          was sent to Amazon Lex V2.</p>
     */
    clientTimestampMillis?: number;
}
export interface PutSessionRequest {
    /**
     * <p>The identifier of the bot that receives the session data.</p>
     */
    botId: string | undefined;
    /**
     * <p>The alias identifier of the bot that receives the session
     *          data.</p>
     */
    botAliasId: string | undefined;
    /**
     * <p>The locale where the session is in use.</p>
     */
    localeId: string | undefined;
    /**
     * <p>The identifier of the session that receives the session data.</p>
     */
    sessionId: string | undefined;
    /**
     * <p>A list of messages to send to the user. Messages are sent in the
     *          order that they are defined in the list.</p>
     */
    messages?: Message[];
    /**
     * <p>Sets the state of the session with the user. You can use this to set
     *          the current intent, attributes, context, and dialog action. Use the
     *          dialog action to determine the next step that Amazon Lex V2 should use in the
     *          conversation with the user.</p>
     */
    sessionState: SessionState | undefined;
    /**
     * <p>Request-specific information passed between Amazon Lex V2 and the client
     *          application.</p>
     *          <p>The namespace <code>x-amz-lex:</code> is reserved for special
     *          attributes. Don't create any request attributes with the prefix
     *             <code>x-amz-lex:</code>.</p>
     */
    requestAttributes?: Record<string, string>;
    /**
     * <p>The message that Amazon Lex V2 returns in the response can be either text or
     *          speech depending on the value of this parameter. </p>
     *          <ul>
     *             <li>
     *                <p>If the value is <code>text/plain; charset=utf-8</code>, Amazon Lex V2
     *                returns text in the response.</p>
     *             </li>
     *          </ul>
     */
    responseContentType?: string;
}
export interface RecognizeTextRequest {
    /**
     * <p>The identifier of the bot that processes the request.</p>
     */
    botId: string | undefined;
    /**
     * <p>The alias identifier in use for the bot that processes the
     *          request.</p>
     */
    botAliasId: string | undefined;
    /**
     * <p>The locale where the session is in use.</p>
     */
    localeId: string | undefined;
    /**
     * <p>The identifier of the user session that is having the
     *          conversation.</p>
     */
    sessionId: string | undefined;
    /**
     * <p>The text that the user entered. Amazon Lex V2 interprets this text.</p>
     */
    text: string | undefined;
    /**
     * <p>The current state of the dialog between the user and the bot.</p>
     */
    sessionState?: SessionState;
    /**
     * <p>Request-specific information passed between the client application
     *          and Amazon Lex V2 </p>
     *          <p>The namespace <code>x-amz-lex:</code> is reserved for special
     *          attributes. Don't create any request attributes with the prefix
     *             <code>x-amz-lex:</code>.</p>
     */
    requestAttributes?: Record<string, string>;
}
/**
 * <p>Represents a stream of events between your application and
 *          Amazon Lex V2.</p>
 */
export declare type StartConversationRequestEventStream = StartConversationRequestEventStream.AudioInputEventMember | StartConversationRequestEventStream.ConfigurationEventMember | StartConversationRequestEventStream.DTMFInputEventMember | StartConversationRequestEventStream.DisconnectionEventMember | StartConversationRequestEventStream.PlaybackCompletionEventMember | StartConversationRequestEventStream.TextInputEventMember | StartConversationRequestEventStream.$UnknownMember;
export declare namespace StartConversationRequestEventStream {
    /**
     * <p>Configuration information sent from your client application to
     *          Amazon Lex V2</p>
     */
    interface ConfigurationEventMember {
        ConfigurationEvent: ConfigurationEvent;
        AudioInputEvent?: never;
        DTMFInputEvent?: never;
        TextInputEvent?: never;
        PlaybackCompletionEvent?: never;
        DisconnectionEvent?: never;
        $unknown?: never;
    }
    /**
     * <p>Speech audio sent from your client application to Amazon Lex V2. Audio
     *          starts accumulating when Amazon Lex V2 identifies a voice and continues until a
     *          natural pause in the speech is found before processing.</p>
     */
    interface AudioInputEventMember {
        ConfigurationEvent?: never;
        AudioInputEvent: AudioInputEvent;
        DTMFInputEvent?: never;
        TextInputEvent?: never;
        PlaybackCompletionEvent?: never;
        DisconnectionEvent?: never;
        $unknown?: never;
    }
    /**
     * <p>DTMF information sent to Amazon Lex V2 by your application. Amazon Lex V2
     *          accumulates the DMTF information from when the user sends the first
     *          character and ends</p>
     *          <ul>
     *             <li>
     *                <p>when there's a pause longer that the value configured for the
     *                end timeout.</p>
     *             </li>
     *             <li>
     *                <p>when there's a digit that is the configured end
     *                character.</p>
     *             </li>
     *             <li>
     *                <p>when Amazon Lex V2 accumulates characters equal to the maximum DTMF
     *                character configuration.</p>
     *             </li>
     *          </ul>
     */
    interface DTMFInputEventMember {
        ConfigurationEvent?: never;
        AudioInputEvent?: never;
        DTMFInputEvent: DTMFInputEvent;
        TextInputEvent?: never;
        PlaybackCompletionEvent?: never;
        DisconnectionEvent?: never;
        $unknown?: never;
    }
    /**
     * <p>Text sent from your client application to Amazon Lex V2. Each
     *             <code>TextInputEvent</code> is processed individually.</p>
     */
    interface TextInputEventMember {
        ConfigurationEvent?: never;
        AudioInputEvent?: never;
        DTMFInputEvent?: never;
        TextInputEvent: TextInputEvent;
        PlaybackCompletionEvent?: never;
        DisconnectionEvent?: never;
        $unknown?: never;
    }
    /**
     * <p>Event sent from the client application to Amazon Lex V2 to indicate that it
     *          has finished playing audio and that Amazon Lex V2 should start listening for
     *          user input.</p>
     */
    interface PlaybackCompletionEventMember {
        ConfigurationEvent?: never;
        AudioInputEvent?: never;
        DTMFInputEvent?: never;
        TextInputEvent?: never;
        PlaybackCompletionEvent: PlaybackCompletionEvent;
        DisconnectionEvent?: never;
        $unknown?: never;
    }
    /**
     * <p>Event sent from the client application to indicate to Amazon Lex V2 that the
     *          conversation is over.</p>
     */
    interface DisconnectionEventMember {
        ConfigurationEvent?: never;
        AudioInputEvent?: never;
        DTMFInputEvent?: never;
        TextInputEvent?: never;
        PlaybackCompletionEvent?: never;
        DisconnectionEvent: DisconnectionEvent;
        $unknown?: never;
    }
    interface $UnknownMember {
        ConfigurationEvent?: never;
        AudioInputEvent?: never;
        DTMFInputEvent?: never;
        TextInputEvent?: never;
        PlaybackCompletionEvent?: never;
        DisconnectionEvent?: never;
        $unknown: [string, any];
    }
    interface Visitor<T> {
        ConfigurationEvent: (value: ConfigurationEvent) => T;
        AudioInputEvent: (value: AudioInputEvent) => T;
        DTMFInputEvent: (value: DTMFInputEvent) => T;
        TextInputEvent: (value: TextInputEvent) => T;
        PlaybackCompletionEvent: (value: PlaybackCompletionEvent) => T;
        DisconnectionEvent: (value: DisconnectionEvent) => T;
        _: (name: string, value: any) => T;
    }
    const visit: <T>(value: StartConversationRequestEventStream, visitor: Visitor<T>) => T;
}
export interface StartConversationRequest {
    /**
     * <p>The identifier of the bot to process the request.</p>
     */
    botId: string | undefined;
    /**
     * <p>The alias identifier in use for the bot that processes the
     *          request.</p>
     */
    botAliasId: string | undefined;
    /**
     * <p>The locale where the session is in use.</p>
     */
    localeId: string | undefined;
    /**
     * <p>The identifier of the user session that is having the
     *          conversation.</p>
     */
    sessionId: string | undefined;
    /**
     * <p>The conversation type that you are using the Amazon Lex V2. If the
     *          conversation mode is <code>AUDIO</code> you can send both audio and
     *          DTMF information. If the mode is <code>TEXT</code> you can only send
     *          text.</p>
     */
    conversationMode?: ConversationMode | string;
    /**
     * <p>Represents the stream of events to Amazon Lex V2 from your application. The
     *          events are encoded as HTTP/2 data frames.</p>
     */
    requestEventStream: AsyncIterable<StartConversationRequestEventStream> | undefined;
}
export interface GetSessionResponse {
    /**
     * <p>The identifier of the returned session.</p>
     */
    sessionId?: string;
    /**
     * <p>A list of messages that were last sent to the user. The messages are
     *          ordered based on the order that your returned the messages from your
     *          Lambda function or the order that messages are defined in the bot.
     *       </p>
     */
    messages?: Message[];
    /**
     * <p>A list of intents that Amazon Lex V2 determined might satisfy the user's
     *          utterance. </p>
     *          <p>Each interpretation includes the intent, a score that indicates how
     *          confident Amazon Lex V2 is that the interpretation is the correct one, and an
     *          optional sentiment response that indicates the sentiment expressed in
     *          the utterance.</p>
     */
    interpretations?: Interpretation[];
    /**
     * <p>Represents the current state of the dialog between the user and the
     *          bot.</p>
     *          <p>You can use this to determine the progress of the conversation and
     *          what the next action might be.</p>
     */
    sessionState?: SessionState;
}
/**
 * <p>Contains the current state of the conversation between the client
 *          application and Amazon Lex V2.</p>
 */
export interface IntentResultEvent {
    /**
     * <p>Indicates whether the input to the operation was text or
     *          speech.</p>
     */
    inputMode?: InputMode | string;
    /**
     * <p>A list of intents that Amazon Lex V2 determined might satisfy the user's
     *          utterance.</p>
     *
     *          <p>Each interpretation includes the intent, a score that indicates how
     *          confident Amazon Lex V2 is that the interpretation is the correct one, and an
     *          optional sentiment response that indicates the sentiment expressed in
     *          the utterance.</p>
     */
    interpretations?: Interpretation[];
    /**
     * <p>The state of the user's session with Amazon Lex V2.</p>
     */
    sessionState?: SessionState;
    /**
     * <p>The attributes sent in the request.</p>
     */
    requestAttributes?: Record<string, string>;
    /**
     * <p>The identifier of the session in use.</p>
     */
    sessionId?: string;
    /**
     * <p>A unique identifier of the event sent by Amazon Lex V2. The identifier is in
     *          the form <code>RESPONSE-N</code>, where N is a number starting with one
     *          and incremented for each event sent by Amazon Lex V2 in the current
     *          session.</p>
     */
    eventId?: string;
}
export interface RecognizeTextResponse {
    /**
     * <p>A list of messages last sent to the user. The messages are ordered
     *          based on the order that you returned the messages from your Lambda
     *          function or the order that the messages are defined in the bot.</p>
     */
    messages?: Message[];
    /**
     * <p>Represents the current state of the dialog between the user and the
     *          bot. </p>
     *          <p>Use this to determine the progress of the conversation and what the
     *          next action may be.</p>
     */
    sessionState?: SessionState;
    /**
     * <p>A list of intents that Amazon Lex V2 determined might satisfy the user's
     *          utterance. </p>
     *          <p>Each interpretation includes the intent, a score that indicates now
     *          confident Amazon Lex V2 is that the interpretation is the correct one, and an
     *          optional sentiment response that indicates the sentiment expressed in
     *          the utterance.</p>
     */
    interpretations?: Interpretation[];
    /**
     * <p>The attributes sent in the request.</p>
     */
    requestAttributes?: Record<string, string>;
    /**
     * <p>The identifier of the session in use.</p>
     */
    sessionId?: string;
}
/**
 * <p>Represents a stream of events between Amazon Lex V2 and your
 *          application.</p>
 */
export declare type StartConversationResponseEventStream = StartConversationResponseEventStream.AccessDeniedExceptionMember | StartConversationResponseEventStream.AudioResponseEventMember | StartConversationResponseEventStream.BadGatewayExceptionMember | StartConversationResponseEventStream.ConflictExceptionMember | StartConversationResponseEventStream.DependencyFailedExceptionMember | StartConversationResponseEventStream.HeartbeatEventMember | StartConversationResponseEventStream.IntentResultEventMember | StartConversationResponseEventStream.InternalServerExceptionMember | StartConversationResponseEventStream.PlaybackInterruptionEventMember | StartConversationResponseEventStream.ResourceNotFoundExceptionMember | StartConversationResponseEventStream.TextResponseEventMember | StartConversationResponseEventStream.ThrottlingExceptionMember | StartConversationResponseEventStream.TranscriptEventMember | StartConversationResponseEventStream.ValidationExceptionMember | StartConversationResponseEventStream.$UnknownMember;
export declare namespace StartConversationResponseEventStream {
    /**
     * <p>Event sent from Amazon Lex V2 to indicate to the client application should
     *          stop playback of audio. For example, if the client is playing a prompt
     *          that asks for the user's telephone number, the user might start to say
     *          the phone number before the prompt is complete. Amazon Lex V2 sends this event
     *          to the client application to indicate that the user is responding and
     *          that Amazon Lex V2 is processing their input.</p>
     */
    interface PlaybackInterruptionEventMember {
        PlaybackInterruptionEvent: PlaybackInterruptionEvent;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Event sent from Amazon Lex V2 to your client application that contains a
     *          transcript of voice audio. </p>
     */
    interface TranscriptEventMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent: TranscriptEvent;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Event sent from Amazon Lex V2 to the client application containing the
     *          current state of the conversation between the user and Amazon Lex V2.</p>
     */
    interface IntentResultEventMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent: IntentResultEvent;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>The event sent from Amazon Lex V2 to your application with text to present
     *          to the user.</p>
     */
    interface TextResponseEventMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent: TextResponseEvent;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>An event sent from Amazon Lex V2 to your client application containing audio
     *          to play to the user. </p>
     */
    interface AudioResponseEventMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent: AudioResponseEvent;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Event that Amazon Lex V2 sends to indicate that the stream is still open
     *          between the client application and Amazon Lex V2 </p>
     */
    interface HeartbeatEventMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent: HeartbeatEvent;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Exception thrown when the credentials passed with the request are
     *          invalid or expired. Also thrown when the credentials in the request do
     *          not have permission to access the <code>StartConversation</code>
     *          operation.</p>
     */
    interface AccessDeniedExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException: AccessDeniedException;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Exception thrown if one of the input parameters points to a resource
     *          that does not exist. For example, if the bot ID specified does not
     *          exist.</p>
     */
    interface ResourceNotFoundExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException: ResourceNotFoundException;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Exception thrown when one or more parameters could not be validated.
     *          The <code>message</code> contains the name of the field that isn't
     *          valid.</p>
     */
    interface ValidationExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException: ValidationException;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Exception thrown when your application exceeds the maximum number of
     *          concurrent requests. </p>
     */
    interface ThrottlingExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException: ThrottlingException;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>An error occurred with Amazon Lex V2.</p>
     */
    interface InternalServerExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException: InternalServerException;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p>Exception thrown when two clients are using the same AWS account,
     *          Amazon Lex V2 bot, and session ID.</p>
     */
    interface ConflictExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException: ConflictException;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p></p>
     */
    interface DependencyFailedExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException: DependencyFailedException;
        BadGatewayException?: never;
        $unknown?: never;
    }
    /**
     * <p></p>
     */
    interface BadGatewayExceptionMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException: BadGatewayException;
        $unknown?: never;
    }
    interface $UnknownMember {
        PlaybackInterruptionEvent?: never;
        TranscriptEvent?: never;
        IntentResultEvent?: never;
        TextResponseEvent?: never;
        AudioResponseEvent?: never;
        HeartbeatEvent?: never;
        AccessDeniedException?: never;
        ResourceNotFoundException?: never;
        ValidationException?: never;
        ThrottlingException?: never;
        InternalServerException?: never;
        ConflictException?: never;
        DependencyFailedException?: never;
        BadGatewayException?: never;
        $unknown: [string, any];
    }
    interface Visitor<T> {
        PlaybackInterruptionEvent: (value: PlaybackInterruptionEvent) => T;
        TranscriptEvent: (value: TranscriptEvent) => T;
        IntentResultEvent: (value: IntentResultEvent) => T;
        TextResponseEvent: (value: TextResponseEvent) => T;
        AudioResponseEvent: (value: AudioResponseEvent) => T;
        HeartbeatEvent: (value: HeartbeatEvent) => T;
        AccessDeniedException: (value: AccessDeniedException) => T;
        ResourceNotFoundException: (value: ResourceNotFoundException) => T;
        ValidationException: (value: ValidationException) => T;
        ThrottlingException: (value: ThrottlingException) => T;
        InternalServerException: (value: InternalServerException) => T;
        ConflictException: (value: ConflictException) => T;
        DependencyFailedException: (value: DependencyFailedException) => T;
        BadGatewayException: (value: BadGatewayException) => T;
        _: (name: string, value: any) => T;
    }
    const visit: <T>(value: StartConversationResponseEventStream, visitor: Visitor<T>) => T;
}
export interface StartConversationResponse {
    /**
     * <p>Represents the stream of events from Amazon Lex V2 to your application. The
     *          events are encoded as HTTP/2 data frames.</p>
     */
    responseEventStream?: AsyncIterable<StartConversationResponseEventStream>;
}
/**
 * @internal
 */
export declare const ActiveContextTimeToLiveFilterSensitiveLog: (obj: ActiveContextTimeToLive) => any;
/**
 * @internal
 */
export declare const ActiveContextFilterSensitiveLog: (obj: ActiveContext) => any;
/**
 * @internal
 */
export declare const AudioInputEventFilterSensitiveLog: (obj: AudioInputEvent) => any;
/**
 * @internal
 */
export declare const AudioResponseEventFilterSensitiveLog: (obj: AudioResponseEvent) => any;
/**
 * @internal
 */
export declare const DeleteSessionRequestFilterSensitiveLog: (obj: DeleteSessionRequest) => any;
/**
 * @internal
 */
export declare const DeleteSessionResponseFilterSensitiveLog: (obj: DeleteSessionResponse) => any;
/**
 * @internal
 */
export declare const GetSessionRequestFilterSensitiveLog: (obj: GetSessionRequest) => any;
/**
 * @internal
 */
export declare const ValueFilterSensitiveLog: (obj: Value) => any;
/**
 * @internal
 */
export declare const ConfidenceScoreFilterSensitiveLog: (obj: ConfidenceScore) => any;
/**
 * @internal
 */
export declare const SentimentScoreFilterSensitiveLog: (obj: SentimentScore) => any;
/**
 * @internal
 */
export declare const SentimentResponseFilterSensitiveLog: (obj: SentimentResponse) => any;
/**
 * @internal
 */
export declare const ButtonFilterSensitiveLog: (obj: Button) => any;
/**
 * @internal
 */
export declare const ImageResponseCardFilterSensitiveLog: (obj: ImageResponseCard) => any;
/**
 * @internal
 */
export declare const MessageFilterSensitiveLog: (obj: Message) => any;
/**
 * @internal
 */
export declare const RuntimeHintValueFilterSensitiveLog: (obj: RuntimeHintValue) => any;
/**
 * @internal
 */
export declare const PutSessionResponseFilterSensitiveLog: (obj: PutSessionResponse) => any;
/**
 * @internal
 */
export declare const RecognizeUtteranceRequestFilterSensitiveLog: (obj: RecognizeUtteranceRequest) => any;
/**
 * @internal
 */
export declare const RecognizeUtteranceResponseFilterSensitiveLog: (obj: RecognizeUtteranceResponse) => any;
/**
 * @internal
 */
export declare const DisconnectionEventFilterSensitiveLog: (obj: DisconnectionEvent) => any;
/**
 * @internal
 */
export declare const DTMFInputEventFilterSensitiveLog: (obj: DTMFInputEvent) => any;
/**
 * @internal
 */
export declare const PlaybackCompletionEventFilterSensitiveLog: (obj: PlaybackCompletionEvent) => any;
/**
 * @internal
 */
export declare const TextInputEventFilterSensitiveLog: (obj: TextInputEvent) => any;
/**
 * @internal
 */
export declare const HeartbeatEventFilterSensitiveLog: (obj: HeartbeatEvent) => any;
/**
 * @internal
 */
export declare const PlaybackInterruptionEventFilterSensitiveLog: (obj: PlaybackInterruptionEvent) => any;
/**
 * @internal
 */
export declare const TextResponseEventFilterSensitiveLog: (obj: TextResponseEvent) => any;
/**
 * @internal
 */
export declare const TranscriptEventFilterSensitiveLog: (obj: TranscriptEvent) => any;
/**
 * @internal
 */
export declare const ElicitSubSlotFilterSensitiveLog: (obj: ElicitSubSlot) => any;
/**
 * @internal
 */
export declare const DialogActionFilterSensitiveLog: (obj: DialogAction) => any;
/**
 * @internal
 */
export declare const RuntimeHintDetailsFilterSensitiveLog: (obj: RuntimeHintDetails) => any;
/**
 * @internal
 */
export declare const RuntimeHintsFilterSensitiveLog: (obj: RuntimeHints) => any;
/**
 * @internal
 */
export declare const SlotFilterSensitiveLog: (obj: Slot) => any;
/**
 * @internal
 */
export declare const IntentFilterSensitiveLog: (obj: Intent) => any;
/**
 * @internal
 */
export declare const InterpretationFilterSensitiveLog: (obj: Interpretation) => any;
/**
 * @internal
 */
export declare const SessionStateFilterSensitiveLog: (obj: SessionState) => any;
/**
 * @internal
 */
export declare const ConfigurationEventFilterSensitiveLog: (obj: ConfigurationEvent) => any;
/**
 * @internal
 */
export declare const PutSessionRequestFilterSensitiveLog: (obj: PutSessionRequest) => any;
/**
 * @internal
 */
export declare const RecognizeTextRequestFilterSensitiveLog: (obj: RecognizeTextRequest) => any;
/**
 * @internal
 */
export declare const StartConversationRequestEventStreamFilterSensitiveLog: (obj: StartConversationRequestEventStream) => any;
/**
 * @internal
 */
export declare const StartConversationRequestFilterSensitiveLog: (obj: StartConversationRequest) => any;
/**
 * @internal
 */
export declare const GetSessionResponseFilterSensitiveLog: (obj: GetSessionResponse) => any;
/**
 * @internal
 */
export declare const IntentResultEventFilterSensitiveLog: (obj: IntentResultEvent) => any;
/**
 * @internal
 */
export declare const RecognizeTextResponseFilterSensitiveLog: (obj: RecognizeTextResponse) => any;
/**
 * @internal
 */
export declare const StartConversationResponseEventStreamFilterSensitiveLog: (obj: StartConversationResponseEventStream) => any;
/**
 * @internal
 */
export declare const StartConversationResponseFilterSensitiveLog: (obj: StartConversationResponse) => any;
